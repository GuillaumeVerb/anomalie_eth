{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Ethereum Transaction Anomaly Detection\n\nThis notebook explores anomaly detection on Ethereum transactions using:\n- Isolation Forest\n- DBSCAN\n\nWe'll compare their performance and visualize the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pathlib import Path\n\n# Custom imports\nfrom src.preprocessing import transform_data\nfrom src.modeling import anomaly_detection_pipeline, prepare_features, tune_isolation_forest, tune_dbscan\n\n# Plotting settings\nplt.style.use('seaborn')\nsns.set_palette('Set2')\n%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load and Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load most recent raw data file\nraw_data_path = max(Path('../data/raw').glob('transactions_*.csv'))\ndf_raw = pd.read_csv(raw_data_path)\n\nprint(f\"Loaded {len(df_raw)} transactions from {raw_data_path.name}\")\ndf_raw.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Transform data and add features\ndf_processed = transform_data(df_raw)\n\nprint(\"\\nFeatures available:\")\nfor col in df_processed.columns:\n    print(f\"- {col}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_distribution(df, column, bins=50):\n    plt.figure(figsize=(12, 5))\n    \n    plt.subplot(1, 2, 1)\n    sns.histplot(data=df, x=column, bins=bins)\n    plt.title(f'Distribution of {column}')\n    \n    plt.subplot(1, 2, 2)\n    sns.histplot(data=df, x=column, bins=bins, log_scale=True)\n    plt.title(f'Log Distribution of {column}')\n    \n    plt.tight_layout()\n\n# Plot key features distributions\nfor feature in ['value', 'gas_price', 'transaction_fee']:\n    plot_distribution(df_processed, feature)\n\n# Plot derived features\nfor feature in ['log_value', 'value_to_gas_ratio', 'tx_density']:\n    plot_distribution(df_processed, feature)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Correlation heatmap of numerical features\nnumerical_features = df_processed.select_dtypes(include=[np.number]).columns\ncorrelation = df_processed[numerical_features].corr()\n\nplt.figure(figsize=(12, 10))\nsns.heatmap(correlation, annot=True, cmap='coolwarm', center=0)\nplt.title('Feature Correlations')\nplt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Hyperparameter Tuning\n\nWe'll optimize the hyperparameters for both models using cross-validation and our custom silhouette score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare features for tuning\nX_scaled, features_used = prepare_features(df_processed)\nprint(f\"Features prepared for tuning: {features_used}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.1 Isolation Forest Tuning\n\nWe'll use GridSearchCV to find the best parameters among:\n- n_estimators: [50, 100, 200]\n- max_samples: [0.5, 1.0]\n- contamination: [0.01, 0.02, 0.05]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tune Isolation Forest\nprint(\"Starting Isolation Forest tuning...\")\nif_best_params, if_best_model = tune_isolation_forest(X_scaled)\n\nprint(\"\\nBest Isolation Forest Parameters:\")\nfor param, value in if_best_params.items():\n    print(f\"- {param}: {value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 DBSCAN Tuning\n\nWe'll use RandomizedSearchCV to find the best parameters among:\n- eps: [0.3, 0.5, 0.7, 1.0]\n- min_samples: [3, 5, 10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tune DBSCAN\nprint(\"Starting DBSCAN tuning...\")\ndbscan_best_params, dbscan_best_model = tune_dbscan(X_scaled)\n\nprint(\"\\nBest DBSCAN Parameters:\")\nfor param, value in dbscan_best_params.items():\n    print(f\"- {param}: {value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.3 Compare Tuned Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get predictions from both tuned models\nif_predictions = if_best_model.predict(X_scaled)\nif_labels = np.where(if_predictions == 1, 0, 1)\n\ndbscan_predictions = dbscan_best_model.fit_predict(X_scaled)\ndbscan_labels = np.where(dbscan_predictions == -1, 1, 0)\n\n# Compare results\nresults_df = pd.DataFrame({\n    'Model': ['Isolation Forest', 'DBSCAN'],\n    'Anomalies Detected': [sum(if_labels), sum(dbscan_labels)],\n    'Anomaly Percentage': [sum(if_labels)/len(if_labels)*100, sum(dbscan_labels)/len(dbscan_labels)*100]\n})\n\nprint(\"Model Comparison after Tuning:\")\nprint(results_df.to_string(index=False))\n\n# Calculate agreement between models\nagreement = (if_labels == dbscan_labels).mean() * 100\nprint(f\"\\nModels agree on {agreement:.2f}% of transactions\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize results from tuned models\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n\n# Plot Isolation Forest results\nscatter1 = ax1.scatter(X_scaled[:, 0], X_scaled[:, 1], c=if_labels, cmap='coolwarm')\nax1.set_title('Tuned Isolation Forest Anomalies')\nax1.set_xlabel(features_used[0])\nax1.set_ylabel(features_used[1])\nplt.colorbar(scatter1, ax=ax1)\n\n# Plot DBSCAN results\nscatter2 = ax2.scatter(X_scaled[:, 0], X_scaled[:, 1], c=dbscan_labels, cmap='coolwarm')\nax2.set_title('Tuned DBSCAN Anomalies')\nax2.set_xlabel(features_used[0])\nax2.set_ylabel(features_used[1])\nplt.colorbar(scatter2, ax=ax2)\n\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Anomaly Detection with Default Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run both models with default parameters\nresults_if = anomaly_detection_pipeline(df_processed, model_type=\"IF\")\nresults_dbscan = anomaly_detection_pipeline(df_processed, model_type=\"DBSCAN\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare results\ndef compare_anomalies(df1, df2):\n    anomalies_if = df1['anomaly_label'].sum()\n    anomalies_dbscan = df2['anomaly_label'].sum()\n    \n    # Calculate agreement between models\n    agreement = (df1['anomaly_label'] == df2['anomaly_label']).mean() * 100\n    \n    print(\"Model Comparison (Default Parameters):\")\n    print(f\"IsolationForest detected: {anomalies_if} anomalies ({anomalies_if/len(df1)*100:.2f}%)\")\n    print(f\"DBSCAN detected: {anomalies_dbscan} anomalies ({anomalies_dbscan/len(df2)*100:.2f}%)\")\n    print(f\"Models agree on {agreement:.2f}% of transactions\")\n\ncompare_anomalies(results_if, results_dbscan)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize anomalies\ndef plot_anomalies(df, feature_x, feature_y, model_name):\n    plt.figure(figsize=(10, 6))\n    \n    # Plot normal and anomalous points\n    normal = df[df['anomaly_label'] == 0]\n    anomalies = df[df['anomaly_label'] == 1]\n    \n    plt.scatter(normal[feature_x], normal[feature_y], \n                c='blue', label='Normal', alpha=0.5, s=50)\n    plt.scatter(anomalies[feature_x], anomalies[feature_y], \n                c='red', label='Anomaly', alpha=0.7, s=100)\n    \n    plt.xlabel(feature_x)\n    plt.ylabel(feature_y)\n    plt.title(f'Anomalies detected by {model_name}')\n    plt.legend()\n    plt.tight_layout()\n\n# Plot for both models\nfor df, name in [(results_if, 'Isolation Forest'), (results_dbscan, 'DBSCAN')]:\n    plot_anomalies(df, 'log_value', 'log_gas_price', name)\n    plot_anomalies(df, 'value_to_gas_ratio', 'fee_to_value_ratio', name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Analyze Anomalous Transactions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare characteristics of normal vs anomalous transactions\ndef analyze_anomalies(df, model_name):\n    normal = df[df['anomaly_label'] == 0]\n    anomalies = df[df['anomaly_label'] == 1]\n    \n    print(f\"\\nAnalysis for {model_name}:\")\n    print(\"\\nMean values:\")\n    for col in ['value', 'gas_price', 'transaction_fee']:\n        print(f\"{col}:\")\n        print(f\"  Normal: {normal[col].mean():.2f}\")\n        print(f\"  Anomalous: {anomalies[col].mean():.2f}\")\n\nanalyze_anomalies(results_if, \"Isolation Forest\")\nanalyze_anomalies(results_dbscan, \"DBSCAN\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Save Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Combine results from both models\nfinal_df = df_processed.copy()\nfinal_df['anomaly_if'] = results_if['anomaly_label']\nfinal_df['anomaly_dbscan'] = results_dbscan['anomaly_label']\nfinal_df['anomaly_agreement'] = (final_df['anomaly_if'] == final_df['anomaly_dbscan']).astype(int)\n\n# Save to processed directory\noutput_path = Path('../data/processed/transactions_labeled.csv')\nfinal_df.to_csv(output_path, index=False)\nprint(f\"Results saved to {output_path}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}